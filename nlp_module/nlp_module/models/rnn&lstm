{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN3ADe3FEWalkWJ+GyIwYqS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"q-k6Z-Z9nfTz"},"outputs":[],"source":["import os\n","import sys\n","import time\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch\n","import torch.nn as nn\n","import matplotlib\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import platform\n","from torch.utils.data import DataLoader\n","import torch.nn.functional as F"]},{"cell_type":"code","source":["class LSTM1(nn.Module):\n","    def __init__(self,vocab_size,embed_size,hidden_size,num_layers,num_classes):\n","      super(LSTM1,self).__init__()\n","      self.embedding=nn.Embedding(vocab_size,embed_size)\n","      #vocab 是序列长度 embed是输入特征长度\n","      #output应该是（）\n","      self.lstm=nn.LSTM(embed_size,hidden_size,num_layers,bidirectional=True,batch_first=True)\n","      self.fc=nn.Linear(2*hidden_size,num_classes)\n","    def forward(self,x):\n","      x=self.embedding(x) #（batch,seq_len,embed_size）\n","      out,_=self.lstm(x)#输出的out维度应该是（batch_size，sample，hiddensize）(2,3,10)\n","      out = torch.cat((out[:, -1, :hidden_size], out[:, 0, hidden_size:]), 1)\n","      out=self.fc(out)\n","      return out\n","\n","input = torch.LongTensor([[1, 2, 3], [4, 5, 6]]) #2个sample 一组三个查询\n","\n","model = LSTM1(10,5,5,2,2)#语料库一共10个值 输入向量长度为5 隐藏为5 层数2 分类2\n","\n","output = model(input)\n","print(output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8LdZd2Gh0Ght","executionInfo":{"status":"ok","timestamp":1724445499476,"user_tz":-60,"elapsed":257,"user":{"displayName":"yue yu","userId":"17383426298810246618"}},"outputId":"5d4c4c0b-03cd-427b-bce7-5c0b58d36c6e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.1254, 0.2012],\n","        [0.1230, 0.1774]], grad_fn=<AddmmBackward0>)\n"]}]},{"cell_type":"code","source":["class LSTMTextClassifier(nn.Module):\n","    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers, **kwargs):\n","        super(LSTMTextClassifier, self).__init__(**kwargs)\n","        self.embedding = nn.Embedding(vocab_size, embed_size)\n","        # 将bidirectional设置为True以获取双向循环神经网络\n","        self.encoder = nn.LSTM(embed_size, num_hiddens, num_layers=num_layers, bidirectional=True)\n","        self.decoder = nn.Linear(4 * num_hiddens, 2)  # 一个output向量长度是2倍的hidden size，有两个output拼接，所以是4倍\n","\n","    def forward(self, inputs):\n","        # inputs的形状是（批量大小，时间步数）\n","        # 因为长短期记忆网络要求其输入的第一个维度是时间维，所以在获得词元表示之前，输入会被转置。\n","        # 输出形状为（时间步数，批量大小，词向量维度）\n","        embeddings = self.embedding(inputs.T)\n","        self.encoder.flatten_parameters()\n","        # 返回上一个隐藏层在不同时间步的隐状态，\n","        # outputs的形状是（时间步数，批量大小，2*隐藏单元数）\n","        outputs, _ = self.encoder(embeddings)\n","        # 连结初始和最终时间步的隐状态，作为全连接层的输入，\n","        # 其形状为（批量大小，4*隐藏单元数）\n","        encoding = torch.cat((outputs[0], outputs[-1]), dim=1)\n","        outs = self.decoder(encoding)\n","        return outs\n","\n","\n","class RNNTextClassifier(nn.Module):\n","    def __init__(self, inp_size, hidden_size, n_class, layer_num, vocab_len, device):\n","        super(RNNTextClassifier, self).__init__()\n","        self.embedding = nn.Embedding(vocab_len, inp_size)\n","\n","        self.device = device\n","        self.hidden_size = hidden_size\n","        self.layer_num = layer_num\n","        self.rnn = nn.RNN(input_size=inp_size, hidden_size=hidden_size, num_layers=layer_num, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, n_class, bias=True)\n","\n","    def forward(self, x):\n","\n","        x_embed = self.embedding(x)  # [batch_size, max_len] -> [batch_size, text_len, embed_len]\n","        outputs, hidden = self.rnn(x_embed)\n","        last_hidden = hidden[-1].squeeze(0)  # [num_layers, bs, hidden_size]  ->  [bs, hidden_size]\n","        fc_output = self.fc(last_hidden)\n","\n","        return fc_output\n","\n","    def forward_bak(self, x):\n","\n","        x_embed = self.embedding(x)  # [batch_size, max_len] -> [batch_size, text_len, embed_len]\n","\n","        bs_, text_len, embed_len = x_embed.shape\n","\n","        hidden_init = self.init_hidden(bs_)\n","        outputs, hidden = self.rnn(x_embed, hidden_init)\n","        # Extract the last hidden state\n","        last_hidden = hidden[-1].squeeze(0)  # [num_layers, bs, hidden_size]  ->  [bs, hidden_size]\n","        last_output = outputs[:, -1, :].squeeze(0)  # bs, sequence len, hidden_size]  ->  [bs, hidden_size]\n","        fc_output = self.fc(last_hidden)\n","\n","        return fc_output\n","\n","    def init_hidden(self, batch_size):\n","        hidden = torch.zeros(self.layer_num, batch_size, self.hidden_size)  # (D∗num_layers, N, H_out)\n","        hidden = hidden.to(self.device)\n","        return hidden\n","\n"],"metadata":{"id":"piWjvkqCuB5x"},"execution_count":null,"outputs":[]}]}